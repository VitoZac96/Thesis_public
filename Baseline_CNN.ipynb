{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Baseline_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtjXZmDhnuyuPart2kYFHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitoZac96/Thesis_public/blob/main/Baseline_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZajFZdhPduhA"
      },
      "source": [
        "# Baseline Model: CNN replicata dal paper: Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline\n",
        "\n",
        "https://arxiv.org/abs/1611.06455 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz8DN_M1d3lj"
      },
      "source": [
        "Installare pacchetti per scaricare la timeseries dei prezzi dell'indice S&P500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZfNwpHlc5Hi"
      },
      "source": [
        "!pip install yfinance\n",
        "!pip install yahoofinancials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwTCtl06dAxU"
      },
      "source": [
        "import yfinance as yf\n",
        "from yahoofinancials import YahooFinancials\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfFVOekzeDon"
      },
      "source": [
        "Funzione per creare gli input: le features che saranno usate nella CNN sono gli \"n_steps\" ritorni passati. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Ha5_H9dGRM"
      },
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyhpycLxetq7"
      },
      "source": [
        "Download the data, select only the closing price and compute the daily percentage change. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRmn5PAdLeo"
      },
      "source": [
        "spx = yf.download('^GSPC', \n",
        "                      start='2015-07-07', \n",
        "                      end='2021-03-01', \n",
        "                      progress=False)\n",
        "spx = spx[\"Adj Close\"].pct_change()[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQbqyERZe5D3"
      },
      "source": [
        "Creare x e y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygHeIw9CdR9R"
      },
      "source": [
        "x, y = split_sequence(spx,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaUUm2__fCZv"
      },
      "source": [
        "Encoding per il classifier: se il ritorno di domani > 0: valore 1; 0 viceversa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbI2NYZ1dU0_"
      },
      "source": [
        "encoded = []\n",
        "for i in y:\n",
        "  if i>0:\n",
        "    encoded.append(1)\n",
        "  else:\n",
        "    encoded.append(0)\n",
        "\n",
        "y_target = pd.DataFrame(encoded).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lth99L8fLos"
      },
      "source": [
        "Train test split e one hot encoding per il classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9QW7jpHdXsq"
      },
      "source": [
        "x_train, x_test, y_train, y_test_val = train_test_split(x, y_target, test_size=0.20, random_state=42)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 2)\n",
        "y_test = keras.utils.to_categorical(y_test_val, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGYlPDAxfjGm"
      },
      "source": [
        "Normalizzazione replicata dal paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yo4WAewdae4"
      },
      "source": [
        "x_train_mean = x_train.mean()\n",
        "x_train_std = x_train.std()\n",
        "x_train = (x_train - x_train_mean)/(x_train_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7C5D0VIddNX"
      },
      "source": [
        "x_test = (x_test - x_train_mean)/(x_train_std)    #### Perch√© non con media e std di se stesso?????\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape + (1,1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,1,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3p8F_ifs6-"
      },
      "source": [
        "Modello replicato dal Paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIkMTbD5dhzx"
      },
      "source": [
        "x = keras.layers.Input(x_train.shape[1:])\n",
        "drop_out = Dropout(0.2)(x)\n",
        "conv1 = keras.layers.Conv2D(128, 8, 1, padding='same')(x) #\n",
        "conv1 = keras.layers.BatchNormalization()(conv1)\n",
        "conv1 = keras.layers.Activation('relu')(conv1)\n",
        "\n",
        "drop_out = Dropout(0.1)(conv1)\n",
        "conv2 = keras.layers.Conv2D(256, 5, 1, padding='same')(conv1)\n",
        "conv2 = keras.layers.BatchNormalization()(conv2)\n",
        "conv2 = keras.layers.Activation('relu')(conv2)\n",
        "\n",
        "drop_out = Dropout(0.1)(conv2)\n",
        "conv3 = keras.layers.Conv2D(128, 3, 1, padding='same')(conv2)\n",
        "conv3 = keras.layers.BatchNormalization()(conv3)\n",
        "conv3 = keras.layers.Activation('relu')(conv3)\n",
        "\n",
        "full = keras.layers.GlobalAveragePooling2D()(conv3)\n",
        "out = keras.layers.Dense(2, activation='sigmoid')(full)\n",
        "\n",
        "\n",
        "model = keras.models.Model(inputs=x, outputs=out)\n",
        "  \n",
        "optimizer = keras.optimizers.Adam()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor=0.5, patience=50, min_lr=0.0001)  #cambiato da 1\n",
        "\n",
        "hist = model.fit(x_train, y_train,  epochs=200, verbose=0, validation_data=(x_test, y_test), callbacks = [reduce_lr])\n",
        "#batch_size=batch_size,\n",
        "\n",
        "#Print the testing results which has the lowest training loss.\n",
        "log = pd.DataFrame(hist.history)\n",
        "#print(log.loc[log['loss'].idxmin]['loss'], log.loc[log['loss'].idxmin]['val_accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50M8DGIIiuAK",
        "outputId": "dc93cd6e-4ed5-42f3-90af-45b6b132eb6e"
      },
      "source": [
        "max(hist.history['val_accuracy'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6302816867828369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6kI8vkiudz"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wExS9ysOi0dg"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opAAzCmxjPji"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}